{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 Trees, Forests, and Bag of Words\n",
    "\n",
    "Official instructions:\n",
    "\n",
    "https://www.cs.tufts.edu/comp/135/2020f/hw4.html\n",
    "\n",
    "This is the *starter code* notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the HW4 starter code\n",
    "from pretty_print_sklearn_tree import pretty_print_sklearn_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data from train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix to path on your local system\n",
    "DATA_DIR = os.path.join(\"../data_product_reviews/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "x_tr_NF.shape: (6346, 7729)\n",
      "y_tr_N.shape : (6346,)\n",
      "mean(y_tr_N) : 0.500\n"
     ]
    }
   ],
   "source": [
    "x_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'x_train.csv.zip'))\n",
    "y_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'y_train.csv'))\n",
    "x_tr_NF = np.minimum(x_tr_df.values, 1.0).copy()\n",
    "y_tr_N = y_tr_df.values[:,0].copy()\n",
    "\n",
    "print(\"Training data\")\n",
    "print(\"x_tr_NF.shape: %s\" % str(x_tr_NF.shape))\n",
    "print(\"y_tr_N.shape : %s\" % str(y_tr_N.shape))\n",
    "print(\"mean(y_tr_N) : %.3f\" % np.mean(y_tr_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data\n",
      "x_va_TF.shape: (792, 7729)\n",
      "y_va_T.shape : (792,)\n",
      "mean(y_va_T) : 0.490\n"
     ]
    }
   ],
   "source": [
    "x_va_df = pd.read_csv(os.path.join(DATA_DIR, 'x_valid.csv.zip'))\n",
    "y_va_df = pd.read_csv(os.path.join(DATA_DIR, 'y_valid.csv'))\n",
    "\n",
    "x_va_TF = np.minimum(x_va_df.values, 1.0).copy()\n",
    "y_va_T = y_va_df.values[:,0].copy()\n",
    "\n",
    "print(\"Validation data\")\n",
    "print(\"x_va_TF.shape: %s\" % str(x_va_TF.shape))\n",
    "print(\"y_va_T.shape : %s\" % str(y_va_T.shape))\n",
    "print(\"mean(y_va_T) : %.3f\" % np.mean(y_va_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heldout Test data\n",
      "x_te_TF.shape: (793, 7729)\n",
      "y_te_T.shape : (793,)\n",
      "mean(y_te_T) : 0.515\n"
     ]
    }
   ],
   "source": [
    "x_te_df = pd.read_csv(os.path.join(DATA_DIR, 'x_test.csv.zip'))\n",
    "y_te_df = pd.read_csv(os.path.join(DATA_DIR, 'y_test.csv'))\n",
    "\n",
    "x_te_TF = np.minimum(x_te_df.values, 1.0).copy()\n",
    "y_te_T = y_te_df.values[:,0].copy()\n",
    "\n",
    "print(\"Heldout Test data\")\n",
    "print(\"x_te_TF.shape: %s\" % str(x_te_TF.shape))\n",
    "print(\"y_te_T.shape : %s\" % str(y_te_T.shape))\n",
    "print(\"mean(y_te_T) : %.3f\" % np.mean(y_te_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = x_tr_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "great\n",
      "time\n",
      "book\n",
      "don't\n",
      "work\n",
      "i_have\n",
      "read\n",
      "...\n",
      "never_get\n",
      "i'd_like\n",
      "loves_it\n",
      "an_author\n",
      "nomin\n",
      "could_give\n",
      "bad_but\n",
      "gap\n"
     ]
    }
   ],
   "source": [
    "for word in vocab_list[:8]:\n",
    "    print(word)\n",
    "print(\"...\")\n",
    "for word in vocab_list[-8:]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pack training and validation sets into big arrays (so we can use sklearn's hyperparameter search tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_LF = np.vstack([x_tr_NF, x_va_TF])\n",
    "yall_L = np.hstack([y_tr_N, y_va_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_L = np.hstack([\n",
    "    -1 * np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * np.ones(y_va_T.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "# Will be used later by all hyperparameter searches\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Decision Trees\n",
    "\n",
    "## 1A: Train a simple tree with depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    max_depth=3, min_samples_split=2, min_samples_leaf=1, criterion='gini')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fit the tree** \n",
    "\n",
    "**TODO Train on the training set** in the next coding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This DecisionTreeClassifier estimator requires y to be passed, but the target y is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-11719a66b12b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimple_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.6/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    156\u001b[0m             X, y = self._validate_data(X, y,\n\u001b[1;32m    157\u001b[0m                                        validate_separately=(check_X_params,\n\u001b[0;32m--> 158\u001b[0;31m                                                             check_y_params))\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/comp135_2020f_env/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requires_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 417\u001b[0;31m                     \u001b[0;34mf\"This {self.__class__.__name__} estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: This DecisionTreeClassifier estimator requires y to be passed, but the target y is None."
     ]
    }
   ],
   "source": [
    "simple_tree.fit(None, None) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Print Tree** \n",
    "\n",
    "Use a helper function from the starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-08f39bf79072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretty_print_sklearn_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/courses/comp135-20f-staffonly/hw_src/hw4/src_starter/pretty_print_sklearn_tree.py\u001b[0m in \u001b[0;36mpretty_print_sklearn_tree\u001b[0;34m(tree_clf, feature_names)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mn_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mchildren_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mchildren_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "pretty_print_sklearn_tree(simple_tree, feature_names=vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B : Find best Decision Tree with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the default predictor\n",
    "# Any hyperparameters here may be overridden by the hyperparameter grid\n",
    "\n",
    "tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='gini', min_samples_split=2, min_samples_leaf=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_hyperparameter_grid_by_name = dict(\n",
    "    max_depth=[2, 8, 32, 128],\n",
    "    min_samples_leaf=[1, 3, 9],\n",
    "    random_state = [101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Build the Grid Search** in the next coding cell\n",
    "\n",
    "Hint: See Lab for Grid Search: https://github.com/tufts-ml-courses/comp135-20f-assignments/blob/master/labs/day13_HyperparameterSearch.ipynb\n",
    "\n",
    "Key Function: sklearn.model_selection.GridSearchCV\n",
    "\n",
    "Key Requirements:\n",
    "\n",
    "* Provide the above tree_hyperparameter_grid_by_name dictionary as the set of hyperparameters to search\n",
    "* Set scoring='balanced_accuracy', since our target metric is balanced accuracy\n",
    "* Set cv=my_splitter so you can use the predefined split we defined earlier.\n",
    "* Set return_train_score=True (we want training set scores as well as test set scores)\n",
    "* Set refit=False (we only want fits on x_tr not on x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_searcher = None # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the search!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-613296043425>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree_grid_searcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxall_LF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myall_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0melapsed_time_sec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time_sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "start_time_sec = time.time()\n",
    "tree_grid_searcher.fit(xall_LF, yall_L)\n",
    "elapsed_time_sec = time.time() - start_time_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataframe of results\n",
    "\n",
    "Move the results of grid search into a nice pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-562682693dd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree_search_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_grid_searcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n\u001b[1;32m      3\u001b[0m     tree_search_results_df.shape[0], elapsed_time_sec))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "tree_search_results_df = pd.DataFrame(tree_grid_searcher.cv_results_).copy()\n",
    "print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n",
    "    tree_search_results_df.shape[0], elapsed_time_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display search results\n",
    "\n",
    "This block will make a pretty printed table of the results of your grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree_search_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3d36d9fb3723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtree_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'param_max_depth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'param_min_samples_leaf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtree_search_results_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtree_search_results_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree_keys\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mean_train_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rank_test_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_fit_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree_search_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('precision', 4)\n",
    "tree_keys = ['param_max_depth', 'param_min_samples_leaf']\n",
    "tree_search_results_df.sort_values(tree_keys, inplace=True)\n",
    "tree_search_results_df[tree_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score', 'mean_fit_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dict of the best hyperparameters\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fb1f0a27497c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Printing a dict of the best hyperparameters\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_grid_searcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "print(\"Printing a dict of the best hyperparameters\")\n",
    "print(tree_grid_searcher.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Build the Best Tree** in the next coding cell\n",
    "\n",
    "This is necessary so you have the specific best performing tree in your workspace.\n",
    "\n",
    "Although you fit many trees in the search, they were not stored, so we need to recreate the best one.\n",
    "\n",
    "Hint: Just feed the best hyperparameters as keyword args to construct the tree. Or see the lab about grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "set_params() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e872f7319181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr_NF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: set_params() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "best_tree = tree.set_params(None) #TODO\n",
    "best_tree.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the best decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c9ab6865e05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_tree' is not defined"
     ]
    }
   ],
   "source": [
    "best_tree.tree_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a7e1d10ba678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretty_print_sklearn_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_tree' is not defined"
     ]
    }
   ],
   "source": [
    "pretty_print_sklearn_tree(best_tree, feature_names=vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    criterion='gini', min_samples_split=2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2A: Best Random Forest via grid search\n",
    "\n",
    "Follow the instructions and using what you learn in 1B to finish this step.\n",
    "\n",
    "This block might take 2-10 minutes. (Takes about 2 min on staff Macbook laptops.)\n",
    "\n",
    "If yours runs significantly longer, try this out on Google Colab instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=125,\n",
    "    criterion='gini',\n",
    "    max_depth=15,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_hyperparameter_grid_by_name = dict(\n",
    "    max_features=[3, 10, 33, 100, 333],\n",
    "    max_depth=[16, 32],\n",
    "    min_samples_leaf=[1],\n",
    "    n_estimators=[125],\n",
    "    random_state=[101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO construct a GridSearchCV object like you did above.\n",
    "\n",
    "forest_searcher = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataframe of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best random forest using the best hyperparameters found in 2B and train it.\n",
    "\n",
    "This is necessary so you have the specific best performing forest in your workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2B & Figure 2 : Feature Importances \n",
    "\n",
    "Access the **feature_importances_** attribute of your trained forest to get a score for each term in our vocabulary.\n",
    "\n",
    "A higher value of this score indicates the feature is \"more important\".\n",
    "\n",
    "In one panel of Figure 2, display a list of the top 10 vocabulary words of your best forest with highest feature importance.\n",
    "\n",
    "In another panel of Figure 2, display a list of 10 randomly chosen terms that have close-to-zero feature importance (use anything with importance less than 0.00001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2.2\n",
    "**Sample Output** (Feel free to print all words and organize them in any software)\n",
    "\n",
    "|**Important Words**|**Unimportant Words**|\n",
    "|:-:|:-:|\n",
    "|I1 |  U1  |\n",
    "|I2 |  U2  |\n",
    "|I3 |  U3  |\n",
    "|I4 |  U4  |\n",
    "|I5 |  U5  |\n",
    "|I6 |  U6  |\n",
    "|I7 |  U7  |\n",
    "|I8 |  U8  |\n",
    "|I9 |  U9  |\n",
    "|I0 |  U0  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Comparison of models\n",
    "\n",
    "### 3A Implementation **TODO**:\n",
    "\n",
    "Selecting the best logistic regression with L1 penalty\n",
    "\n",
    "Table 3 in Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.LogisticRegression(\n",
    "    penalty='l1', solver='saga', random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_hyperparameter_grid_by_name = dict(\n",
    "    C=np.logspace(-4, 4, 9),\n",
    "    max_iter=[20, 40], # sneaky way to do \"early stopping\" \n",
    "                       # we'll take either iter 20 or iter 40 in training process, by best valid performance\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Selecting the best logistic regression with L1 penalty\n",
    "Hint: Follow 1B and 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3: Comparison of methods on the bag-of-words to sentiment classification task.\n",
    "\n",
    "Please report balanced accuracy on the train, valid, and test sets, to 3 digits of precision\n",
    "\n",
    "**Sample Output** (Feel free to print all values and organize them in any software)\n",
    "\n",
    "|**method**|**train**|**valid**|**test**|\n",
    "|:-|:-:|:-:|:-:|\n",
    "|L1-penalized LogisticRegression\t|0.123\t|0.456\t|0.890|\n",
    "|best RandomForest\t|0.123\t|0.456\t|0.890|\n",
    "|best Tree\t|0.123\t|0.456\t|0.890|\n",
    "|simple Tree\t|0.123\t|0.456\t|0.890|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
